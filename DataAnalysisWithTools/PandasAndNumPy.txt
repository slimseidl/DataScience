Pandas

pandas functions:

    - df.head() 
    - df.columns
    - .shape 
        - returns the shape of the DataFrame
    - .dtypes
        - returns each datatype of the columns
    - .info()
        - returns info about the DataFrame including the number of non-null values
    - .nunique()
        - returns number of unique values for each column
    - .describe()
        - returns summary statistics, e.g. count, mean
    - .tail()
    - .loc
        - uses labels of rows or columns to select data,
        - df_means = df.loc[:,'id':'fractal_dimension_mean']
        - location 
        - first : is rows, second is columns 
            [:,:] = all rows / columns 
    - .iloc 
        - uses the index numbers
        - df_means = df.iloc[:,:12]
        - index location

    - numpy.r_ 
        - concatenates slices of a df 
        - use with iloc to select separated ranges of columns
        - df_se = df.iloc[:, np.r_[0:2,12:22]]
            - selects all rows, first two columns, then cols 12 - 21 

    - .mean()
        - compute mean of a column / feature 
        - mean = df["column"].mean()
    -.fillna()
        - fill in missing values of a col with a value 
        - fill in with mean
            - df["column"] = df["column"].fillna(mean)
        - inplace parameter - make changes in place rather than new col 
            - df["column"].fillna(mean, inplace=True)
    - .duplicated()
        - view duplicated values 
        - sum(df.duplicated()) returns a count of duplicates 
    - .drop_duplicates(inplace=True)
        - drops duplicates 
    - df['col'] = pd.todatetime(df['col'])
        - converts to datetime format 
    - .drop()
        - drop features / cols that arent relevant to dataset 
        - df.drop(columns=["col1", "col2"], inplace=True)
        - df.drop(["col1", "col2"], axis=1, inplace=True)
            - axis is row / col 
            - 0 = row 
            - 1 = col 
    - .rename()
        - rename the columns and make them uniform
        - can work with either a dictionary or a function that maps the old names to the new ones
            - df.rename({"sales team": "group"}, axis=1, inplace=True)
                - renames sales team to group 
        - rename with a function 
            - columns = lambda x: x.strip().lower().replace(" ","_"), inplace=True
            - this method is easy to work with 
    - df.query()
        - to query a dataframe without repeating df name 
        - df_2wd = df[df["drive"] == "2WD"] versus df_2wd = df.query('drive == "2WD"')
        - Numeric Data:
            - df_low_displ = df[df.displ < 3] versus df_low_displ = df.query('displ < 3')
    - .isnull()
        - view nulls across dataset 
        - use df.isnull().sum() to view a count of nulls from each column in the df 
    - .dropna(inplace=True)
        - Drop rows with missing values 
    - .astype()
        - Uses dictionary mappings to cast values to different data types
            - df['column_A'] = df.astype({'column_A': 'int32'})
            - better for multiple vals 
        - Casting using series rather than dict 
            - df['column_A'] = df['column_A'].astype('int32')
    - .dtypes 
        - data types for cols 
        - No parentheses
    - .value_counts()
        - count number of unique values in each col 
    - .str.contains('value')
        - search for a value in a string 
    - .apply()
        - Apply a function to a column 
        - for c in split_columns:
            df1[c] = df1[c].apply(lambda x: x.split("/")[0]) 
    - pd.concat()
        - concatenate dataframes 
        - default is concat on rows (axis=0)
            - stack dfs on top of each other by adding rows to the end 
        - axis = 1
            - combines horizontally, adding more columns to the end of df 
    - np.iinfo() and np.finfo()
        - see the minimum and maximum values that can be represented by each size
        - np.iinfo("int16")
            - columns can hold values between -32,768 and +32,767
    - category
        - If a string's column is repetitive or not very unique, it can be changed to category
        - reduces space
    - pd.merge()
        - joins like sql tables 
        - left, right, inner, outer 
        - how param 
            - how="inner" 
        - on param 
            - on = "key to join on" 
            - left on
                - left side key if column names are different 
            - right on 
                - right side key if col names are different 
        - df_combined = pd.merge(df_08, df_18, how="inner", left_on="model_2008", right_on="model")
    - pd.DataFrame.values.tolist()
        - explodes a list value in a column to new columns 
            - see last section of fueleconomy.ipynb 
    - np.random.rand(25,5)
        - creates a random array 
        - .rand paramter indicates size of array 
            - A list of 25 lists 
            - 5 elements in every list 
    - pd.DataFrame 
        - Converts values to a pandas dataframe
    .tolist()
        - converts list items to cell values 
        - each of the 25 lists becomes a separate cell value 
    - .explode()
        - explodes a list in a column to separate rows for each list
            - see last section of fueleconomy.ipynb 
        - df.explode(column="list_values")
            - column param to specify column(s)
    .groupby()
        - group columns and compute statistics for them 
        - df.groupby("workclass").mean(numeric_only=True)
        - df.groupby(["col1","col2"]).mean(numeric_only=True)
        - as_index parameter 
            - False to keep "workclass" and "race" as non index values
            - use number indices instead 
    - .sum()
        - axis parameter 
        - 0 for sum on rows 
        - 1 for sum columns 
    - .sort_values()
        - by = "column to sort by"
        - ascending = t or f 
    - Measures of Center 
        - .mean 
        - .median()
            - center value in a sorted list 
        - .mode()
            - highest frequency
    - Measures of Spread 
        - quantile()
            - values that split a group of data into equal parts, helping to show how the data is spread out
            - [1, 2, 3, 4, 5]
                - 25% quantile = 2
                - 50% quantile = 3 (commonly referred to as the median)
                - 75% quantile = 4
        - .std()
            - standard deviation 
            - shows how much the individual numbers in a group differ from the average
                - gives an idea of how spread out the data is
            - stddev = sqrt of the sum of ((value - mean)squared) / number of values 
                - 1, 2, 3, 4, 5
                    - mean is 3
                    - subtract mean from each 
                    - -2, -1, 0, 1, 2
                        - square each value 
                        - 4, 1, 0, 1, 4
                        - mean for values 
                            - 10 / 4 = 2.5 
                                - std dev = sqrt(2.5) = 1.581 
                                - or std dev = 2.5^0.5 = 1.581
        - .var() 
            - Variance is a measure that helps us understand how the numbers in a group differ from their average
            - sense of how scattered or clustered the data is
            - square the std dev 
        



Wrangling vs. EDA 

- Wrangling = gather, clean, assess
- EDA = explore / augment data 
    - Engineering new features and removing outliers 

Gathering Data

- Download Data
- API 
    - API Layer
        - A platform offering ready-to-use APIs for structured data access
        - provides data only if the provider already exposes it via API
- Scraping 
    - Scrapy
        - powerful Python-based web scraping framework designed for large-scale crawls
- Database 


CSV Files 

    - pd.read_csv
    - Parameters!
        - filepath = file path of csv file 
        - sep = separator (, for csv files)
            - sep = : 
        - header = header of csv 
            - header = 2 uses row 2 as column headers 
            - header = none does not use any headers

        - index_col = which column is t he index, or create a new numeric one 
            - df = pd.read_csv('student_scores.csv', index_col='Name')
            - can be more than 1 

        - names = custom labels for columns 
            - labels = ['id', 'name', 'attendance', 'hw', 'test1', 'project1', 'test2', 'project2', 'final']
            - df = pd.read_csv('student_scores.csv', names=labels)
                - uses names as column headers 
            - df_powerplant = pd.read_csv('powerplant_data.csv',header=0,names= ["temp", "exhaust", "pressure", "humidity", "energy"])
                - header = 0 removes original col names, replaces with names 

    - pd.to_csv
    - Parameters 
        - index = FALSE 
            - to_csv() will store our index unless we tell it not to
            - makes it not store the index in an unnamed column 

- Communicating Results 

    Numpy methods 
        - Speeds up processes
        - built for quick mathematical computation 
        
        - np.mean()
            - comptue mean, super fast 
        - pandas is built on top of numpy, so computations are very fast 
